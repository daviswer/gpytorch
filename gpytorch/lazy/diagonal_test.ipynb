{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from torch.autograd import Variable\n",
    "from gpytorch.kernels import RBFKernel, GridInterpolationKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable\n",
    "from gpytorch.lazy import ToeplitzLazyVariable\n",
    "\n",
    "class KissGPModel(gpytorch.GPModel):\n",
    "    def __init__(self):\n",
    "        likelihood = GaussianLikelihood(log_noise_bounds=(-3, 3))\n",
    "        super(KissGPModel, self).__init__(likelihood)\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        covar_module = RBFKernel(log_lengthscale_bounds=(-100, 100))\n",
    "        covar_module.log_lengthscale.data = torch.FloatTensor([-2])\n",
    "        self.grid_covar_module = GridInterpolationKernel(covar_module)\n",
    "        self.initialize_interpolation_grid(300, grid_bounds=[(0, 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.grid_covar_module(x)\n",
    "        return GaussianRandomVariable(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KissGPModel()\n",
    "\n",
    "n = 1000\n",
    "x = Variable(torch.rand(n))\n",
    "x2 = Variable(torch.rand(n))\n",
    "y = Variable(torch.rand(n))\n",
    "model.condition(x, y)\n",
    "toep_var = model.forward(x).covar()\n",
    "model.condition(x2, y)\n",
    "toep_var2 = model.forward(x2).covar()\n",
    "\n",
    "rhs = torch.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "toep_var_eval = toep_var.evaluate().data\n",
    "toep_var_2_eval = toep_var2.evaluate().data\n",
    "\n",
    "actual = (toep_var_eval * toep_var_2_eval).matmul(rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999946867\n",
      "torch.Size([1000, 1])\n",
      "torch.Size([1000, 1])\n",
      "torch.Size([1, 1000, 15])\n",
      "torch.Size([1, 15])\n",
      "U.size:\n",
      "torch.Size([1000, 1])\n",
      "in _batch_mv\n",
      "torch.Size([1, 1, 1000])\n",
      "torch.Size([1, 1000])\n",
      "torch.Size([1, 1])\n",
      "in _batch_mv\n",
      "torch.Size([1, 1000, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000])\n",
      "torch.Size([1000, 1000]) torch.Size([1000, 1000]) torch.Size([1000]) torch.Size([1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [1] and src [1000] to have the same number of elements, but got 1 and 1000 elements respectively at /Users/soumith/miniconda2/conda-bld/pytorch_1501999754274/work/torch/lib/TH/generic/THTensorCopy.c:86",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf64f7271738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclosure_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoep_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mQ_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStochasticLQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanczos_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mQ_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mT_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ruihanwu/playground/gpytorch/gpytorch/utils/lanczos_quadrature.py\u001b[0m in \u001b[0;36mlanczos_batch\u001b[0;34m(self, matmul_closure, rhs_vectors)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [1] and src [1000] to have the same number of elements, but got 1 and 1000 elements respectively at /Users/soumith/miniconda2/conda-bld/pytorch_1501999754274/work/torch/lib/TH/generic/THTensorCopy.c:86"
     ]
    }
   ],
   "source": [
    "from gpytorch.utils import StochasticLQ\n",
    "\n",
    "iter_num = 15\n",
    "\n",
    "z = torch.randn(n, 1)\n",
    "z = z / torch.norm(z, 2, 0)\n",
    "\n",
    "print z[:, 0].norm()\n",
    "def closure_1(rhs):\n",
    "    return toep_var.matmul(Variable(rhs)).data\n",
    "Q_1, T_1 = StochasticLQ(max_iter=iter_num).lanczos_batch(closure_1, z)\n",
    "Q_1 = Q_1[0]\n",
    "T_1 = T_1[0]\n",
    "\n",
    "z = torch.randn(n, 1)\n",
    "z = z / z.norm()\n",
    "def closure_2(rhs):\n",
    "    return toep_var2.matmul(Variable(rhs)).data\n",
    "Q_2, T_2 = StochasticLQ(max_iter=iter_num).lanczos_batch(closure_2, z)\n",
    "Q_2 = Q_2[0]\n",
    "T_2 = T_2[0]\n",
    "\n",
    "print Q_1.size()\n",
    "print Q_1.t().matmul(Q_1)\n",
    "\n",
    "res = (Q_1.matmul(T_1).matmul(Q_1.t()).matmul(rhs.diag()).matmul(Q_2).matmul(T_2).matmul(Q_2.t())).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.5798656578\n"
     ]
    }
   ],
   "source": [
    "print ((res - actual).norm() / actual.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
